<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Linyan Huang</title>
  
  <meta name="author" content="Linyan Huang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="u8S0zPtl4mCVVwZ0YUFtVrgQnq9eBhl9N4W83xsN0xw" />
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Linyan Huang (黄琳焱)</name><br />
		<font size="2"> linyan [dot] cv [At] gmail [dot] com <font size="2">
              </p>
              <p>I am a second year CS Master student at Xiamen University. 
              </p>
              <p style="text-align:center">
                <a href="mailto:linyan.cv@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=eV1-0BcAAAAJ&hl=en&oi=sra">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/linyanAI/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/huanglinyan.png"><img style="width:50%;max-width:50%" alt="profile photo" src="images/huanglinyan.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
		 I am interestied in 2D vision and autonomous driving. Currently, I am focusing on the <b> panoptic segmentation, 3D object detection, and autonomous driving perception.<b> If you are interested in collaboration for those topics, please feel free to drop me a email.
              </p>
            </td>
          </tr>
	
		
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publication & Project</heading>
            </td>
          </tr>
		
	</tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/GAPretrain.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2304.03105" id="MCG_journal">
                <papertitle>Geometric-aware Pretraining for Vision-centric 3D Object Detection</papertitle>
              </a>
              <br>
		    <b> Linyan Huang </b>, Huijie Wang, Jia Zeng, Shengchuan Zhang, Liujuan Cao, Junchi Yan, Hongyang Li
              <br>
              arXiv, 2023
              <br>
              <p></p> 
              <p> Geometric-aware Pretraining for camera-only methods. Plug-and-Play methods for various detectors such as BEVFormer and BEVDepth. </p>
            </td>
          </tr>
	
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/yoso.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2303.14651" id="MCG_journal">
                <papertitle> You Only Segment Once: Towards Real-Time Panoptic Segmentation </papertitle>
              </a>
              <br>
		    Jie Hu,<b> Linyan Huang </b>, Tianhe Ren, Shengchuan Zhang, Rongrong Ji, Liujuan Cao
              <br>
             <b>CVPR</b>, 2023
              <br>
              <p></p> 
              <p>  YOSO designed a light-weight feature pyramid aggregator and a seperable dynamic convolution attention module to speed up the segmentation pipeline. To the best of our knowledge, YOSO is the first real-time panoptic segmentation framework with competitive performance compared to state-of-the-art methods. </p>
            </td>
         </tr>


	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Activities</heading>
	      <p>
		      CVPR2023, ICCV2023 reviewer.
	      </p>
            </td>
          </tr>
